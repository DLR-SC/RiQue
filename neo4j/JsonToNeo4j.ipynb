{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import unicode_literals\n",
    "import warnings\n",
    "import ruamel.yaml as yaml\n",
    "\n",
    "warnings.simplefilter('ignore', yaml.error.UnsafeLoaderWarning)\n",
    "import json \n",
    "import py2neo # library used to comunicate with database\n",
    "from py2neo import Graph, Node, Relationship, Database, RelationshipMatcher\n",
    "from py2neo import Path\n",
    "\n",
    "import logging\n",
    "import rasa_nlu # 0.13.2 version\n",
    "from rasa_nlu.model import Interpreter\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.policies.keras_policy import KerasPolicy\n",
    "from rasa_core.policies.memoization import MemoizationPolicy\n",
    "from rasa_core.interpreter import RasaNLUInterpreter # to use rasa core model\n",
    "\n",
    "    \n",
    "import pypher\n",
    "from pypher import Pypher, __\n",
    "from pypher.builder import Param\n",
    "from neo4j.v1 import GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create object of the graph database along with its username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"http://localhost:7474\", auth=(\"neo4j\", \"123456\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Json file to graphs\n",
    "\n",
    "In order to convert json source file to graph database, we use neo4j database which uses cypher query language. To visualize the graph, login to  http://localhost:7474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json file\n",
    "with open('../../data/rte.json') as data_file:\n",
    "    json_ = json.load(data_file)\n",
    "\n",
    "# write cypher query\n",
    "query = '''\n",
    "\n",
    "WITH {json} as document\n",
    "UNWIND document.bundles AS p\n",
    "MERGE(rce: project {name:toLower(document.name), \n",
    "    className: toLower(document.eClass), timeStamp: document.modelTimestamp})\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "MERGE (b: bundles {name:toLower(p.name), className:toLower(p.eClass)}) SET b.symbolicName=toLower(p.symbolicName)\n",
    "MERGE(rce)-[:has_bundles]->(b)\n",
    "\n",
    " FOREACH (imp IN p.imports | \n",
    "   MERGE(im: PackagesImports {name:toLower(substring(imp.ref, 3,10))}) SET im.FullName=toLower(imp.ref)\n",
    "\n",
    "\n",
    " MERGE(b)-[:Imports]->(im))\n",
    "\n",
    "\n",
    "FOREACH (exp IN p.exports | \n",
    "    MERGE(ex: PackagesExports {name:toLower(substring(exp.ref, 3,10))} ) SET ex.FullName=toLower(exp.ref) \n",
    "    MERGE(b)-[:Exports]->(ex))\n",
    "\n",
    "FOREACH (pkg IN p.packages | \n",
    "\n",
    "    MERGE(pk: Packages {name:toLower(right(pkg.ref,3))} ) SET pk.FullName=toLower(pkg.ref)\n",
    "    MERGE(b)-[:Uses_Pkgs]->(pk))\n",
    "    \n",
    "    // Iterate through components\n",
    "    \n",
    "FOREACH (comp IN p.components | \n",
    "\n",
    "    MERGE (b)-[:Uses_Components]-> (c: Components {name:toLower(comp.name)} ) \n",
    "        SET c.className=toLower(comp.eClass), \n",
    "        c.implementation = toLower(comp.implementation.ref),\n",
    "        c.bundle = toLower(comp.bundle.ref)\n",
    "        \n",
    "        // Iterate through provided services\n",
    "        FOREACH (service in comp.providedServices| \n",
    "             MERGE(c)-[:uses_services]->(sr: ComponentServices \n",
    "                                     {name: toLower(substring(service.ref, 3, size(service.ref)-1)) }) )\n",
    "        \n",
    "    )\n",
    "\n",
    "FOREACH (pkgfrag IN p.packageFragments |\n",
    "    MERGE(b)-[:Pkg_fragment]->(fragment: PackageFragments {name:toLower(pkgfrag.eClass)}) \n",
    "            SET fragment.className = toLower(pkgfrag.eClass)\n",
    "    MERGE(fragment)-[:Pack_By_Frag]->(pack: FragPackages {name:toLower(pkgfrag.package.ref)})\n",
    "    MERGE(fragment)-[:Bundle_By_Frag]->\n",
    "            (bund: FragBundle {name:toLower(substring(pkgfrag.bundle.ref, 3, size(pkgfrag.bundle.ref)-1)) })\n",
    "\n",
    "    // Since compilation units is list so we need to iterate\n",
    "    FOREACH (cmp IN pkgfrag.compilationUnits | \n",
    "        MERGE(fragment)-[:compiled_By]->(u: Units{name:toLower(substring(cmp.name, 0, size(cmp.name)-5))}) \n",
    "                    SET u.className = toLower(cmp.eClass),\n",
    "                    u.Loc = cmp.LOC\n",
    "\n",
    "        // go through PkgFragment inside compilationUnits -> packageFragment\n",
    "        MERGE(u)-[:compiledUnits_pkgFragment]->\n",
    "        (CPkFrag: compiledUF \n",
    "                {name:toLower(substring(cmp.packageFragment.ref, 3, size(cmp.packageFragment.ref)-2))}) \n",
    "\n",
    "        // go through PkgFragment inside compilationUnits -> topLevelType\n",
    "\n",
    "        MERGE(u)-[:compiledUnits_topLevelType]->\n",
    "        (CPtpLevelType: compiledTopLevelType {name:toLower(cmp.topLevelType.name)}) \n",
    "                    SET  CPtpLevelType.className = toLower(cmp.topLevelType.eClass),\n",
    "        CPtpLevelType.visibility = toLower(cmp.topLevelType.visibility), \n",
    "        CPtpLevelType.qualifiedName = toLower(cmp.topLevelType.qualifiedName)\n",
    "\n",
    "        // Inside topLevelType > compilationUnit\n",
    "\n",
    "        MERGE(CPtpLevelType) -[:topLevelType_compilationUnit]->\n",
    "        (topLevel_cUnit: compilationUnit {name: toLower(cmp.topLevelType.compilationUnit.ref) } ) \n",
    "        SET topLevel_cUnit.ref = toLower(cmp.topLevelType.compilationUnit.ref)\n",
    "\n",
    "\n",
    "        // Inside topLevelType > references\n",
    "\n",
    "        FOREACH (refer IN cmp.topLevelType.references |\n",
    "            MERGE(CPtpLevelType)-[:topLevelType_reference]->\n",
    "                    (referTL: References {name:tolower(substring(refer.ref, 31, size(refer.ref)-1)) })\n",
    "            SET referTL.ref = tolower(refer.ref)\n",
    "        )\n",
    "        \n",
    "        // Inside topLevelType > External references\n",
    "\n",
    "        FOREACH (erefer IN cmp.topLevelType.externalReferences |\n",
    "            MERGE(CPtpLevelType)-[:topLevelType_EReference]->\n",
    "                (ereferTL: eReferences {name:tolower(erefer.ref)})\n",
    "            SET ereferTL.ref = tolower(erefer.ref)\n",
    "        )\n",
    "        \n",
    "        // Inside topLevelType > Constructors\n",
    "\n",
    "        FOREACH (const IN cmp.topLevelType.constructors |\n",
    "            MERGE(CPtpLevelType)-[:topLevelType_Const]->\n",
    "                (constTL: Constructor {name:tolower(const.eClass)})\n",
    "            SET constTL.eClass = tolower(const.eClass),\n",
    "                constTL.visibility = tolower(const.visibility),\n",
    "                constTL.LOC = const.LOC\n",
    "        )\n",
    "        \n",
    "        // Inside topLevelType > methods\n",
    "\n",
    "        FOREACH (methd IN cmp.topLevelType.methods |\n",
    "            MERGE(CPtpLevelType)-[:Methods_Contains]->\n",
    "                (methodTL: Methods {name:tolower(methd.name)})\n",
    "            SET methodTL.eClass = tolower(methd.eClass),\n",
    "                methodTL.name = tolower(methd.name),\n",
    "                methodTL.visibility = tolower(methd.visibility),\n",
    "                methodTL.LOC = methd.LOC\n",
    "        )\n",
    "        \n",
    "        // Inside topLevelType > fields\n",
    "\n",
    "        FOREACH (field IN cmp.topLevelType.fields |\n",
    "            MERGE(CPtpLevelType)-[:Methods_Contains]->\n",
    "                (fieldTL: Methods {name:tolower(field.name)})\n",
    "            SET fieldTL.eClass = tolower(field.eClass),\n",
    "                fieldTL.name = tolower(field.name),\n",
    "                fieldTL.visibility = tolower(field.visibility),\n",
    "                \n",
    "                fieldTL.modify_0 = tolower(field.modifier[0]),\n",
    "                fieldTL.modify_1 = tolower(field.modifier[1])\n",
    "\n",
    "                \n",
    "                \n",
    "        )\n",
    "        \n",
    "    )\n",
    ")\n",
    "\n",
    "MERGE (v: Version {name:(\"Version \" + p.version.major)}) SET \n",
    "  v.className = tolower(p.version.eClass),\n",
    "  v.major=p.version.major, \n",
    "  v.minor=p.version.minor,\n",
    "  v.micro=p.version.micro,\n",
    "  v.qualifier=tolower(p.version.qualifier)\n",
    "  \n",
    " MERGE(b)-[:VersionNum]->(v)  \n",
    " \n",
    "\n",
    "// Iterate through packages on ground level (fields inside packages are not completed)\n",
    "WITH {json} as document\n",
    "UNWIND document.packages AS s\n",
    "     MERGE (pkg: packages {name:tolower(s.name), className:s.eClass}) \n",
    "        SET pkg.qualifiedName = tolower(s.name)\n",
    "\n",
    "MERGE(rce)-[:has_packages]->(pkg)\n",
    " \n",
    "// Iterate through services\n",
    "\n",
    "WITH {json} as document\n",
    "UNWIND document.services AS s\n",
    "\n",
    "MERGE (ser: service {name:tolower(s.interfaceName), className:s.eClass}) \n",
    "        SET ser.interface = tolower(s.interface.ref)\n",
    "        \n",
    "MERGE(rce)-[:has_services]->(ser)\n",
    "\n",
    "// Iterate through externalTypes\n",
    "\n",
    "// WITH {json} as document\n",
    "// UNWIND document.externalTypes AS e\n",
    " \n",
    "// MERGE (eTyp: eTypes {name:tolower(e.qualifiedName), className:tolower(e.eClass)}) \n",
    "MERGE(rce)-[:has_externalTypes]->(eTyp)\n",
    "'''\n",
    "\n",
    "\n",
    "# To get relations of particular node\n",
    "# MATCH (n:classes) where n.name='RCE Excel Component Execution' return (n)-[]->()\n",
    "\n",
    "#send query to the database\n",
    "graph.run(query, json=json_).data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To execute other cells is not necessary, as json file is already converted to graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a.name': 'RCE Excel Component GUI Bundle'},\n",
       " {'a.name': 'RCE Input Provider Component GUI'},\n",
       " {'a.name': 'RCE XML Merger Component Common'},\n",
       " {'a.name': 'RCE Parametric Study Component Execution'},\n",
       " {'a.name': 'RCE Joiner Component GUI'},\n",
       " {'a.name': 'RCE Components Evaluation Memory Execution'},\n",
       " {'a.name': 'RCE CPACS Writer Component Common'},\n",
       " {'a.name': 'RCE Components DOE Execution'},\n",
       " {'a.name': 'RCE Excel Component Execution'},\n",
       " {'a.name': 'RCE CPACS VAMPzero Initializer Component Execution'},\n",
       " {'a.name': 'RCE XML Loader Component Common'},\n",
       " {'a.name': 'RCE Input Provider Component Execution'},\n",
       " {'a.name': 'RCE Joiner Component Execution'},\n",
       " {'a.name': 'RCE Components DOE Common'},\n",
       " {'a.name': 'RCE Cluster Component Common'},\n",
       " {'a.name': 'RCE Database Component Execution'},\n",
       " {'a.name': 'RCE Components Switch GUI'},\n",
       " {'a.name': 'RCE Decrypter Component Common (Example Component)'},\n",
       " {'a.name': 'RCE XML Merger Component Execution'},\n",
       " {'a.name': 'RCE OutputWriter Component Common'},\n",
       " {'a.name': 'RCE Input Provider Component Common'},\n",
       " {'a.name': 'RCE CPACS VAMPzero Initializer Component Common'},\n",
       " {'a.name': 'RCE Decrypter Component Execution (Example Component)'},\n",
       " {'a.name': 'RCE Components Output Writer Execution'},\n",
       " {'a.name': 'RCE Encrypter Component Common (Example Component)'},\n",
       " {'a.name': 'RCE Components Evaluation Memory GUI'},\n",
       " {'a.name': 'RCE Components Switch Common'},\n",
       " {'a.name': 'RCE Database Component Common'},\n",
       " {'a.name': 'RCE TiGL Viewer Component Execution'},\n",
       " {'a.name': 'RCE XML Loader Component Execution'},\n",
       " {'a.name': 'RCE Database Component GUI'},\n",
       " {'a.name': 'RCE Decrypter Component GUI (Example Component)'},\n",
       " {'a.name': 'RCE Components Switch Execution'},\n",
       " {'a.name': 'RCE Joiner Component Common'},\n",
       " {'a.name': 'RCE XML Loader Component GUI'},\n",
       " {'a.name': 'RCE Toolkit - Core'},\n",
       " {'a.name': 'RCE Parametric Study Component Common'},\n",
       " {'a.name': 'RCE Encrypter Component GUI (Example Component)'},\n",
       " {'a.name': 'RCE TiGL Viewer Component GUI'},\n",
       " {'a.name': 'RCE Encrypter Component Execution (Example Component)'},\n",
       " {'a.name': 'RCE CPACS VAMPzero Initializer Component GUI'},\n",
       " {'a.name': 'RCE Components Evaluation Memory Common'},\n",
       " {'a.name': 'RCE XML Merger Component GUI'},\n",
       " {'a.name': 'RCE Cluster Component GUI'},\n",
       " {'a.name': 'RCE CPACS Writer Component GUI'},\n",
       " {'a.name': 'RCE CPACS Writer Component Execution'},\n",
       " {'a.name': 'RCE Components DOE GUI'},\n",
       " {'a.name': 'RCE Toolkit - Common Modules'},\n",
       " {'a.name': 'RCE Excel Component Common Bundle'},\n",
       " {'a.name': 'RCE Cluster Component Execution'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1 = '''\n",
    "Match (a:bundles) Return a.name\n",
    "'''\n",
    "graph.run(query1).data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# query from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(RCE Excel Component GUI Bundle)-[:Imports {}]->(bundles.48),\n",
       " (RCE Excel Component GUI Bundle)-[:Imports {}]->(bundles.47)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v = 'RCE Excel Component GUI Bundle'\n",
    "nodes = graph.nodes.match(\"bundles\", name=v).first()\n",
    "list(graph.relationships.match((nodes, None), \"Imports\") \n",
    "              .limit(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To delete the existing nodes\n",
    "# graph.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RASA NLU \n",
    "\n",
    "For configuring rasa nlu needs training data(can be in .md or .json format) and model configuration file( .yml format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training nlu model\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "training nlu completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "class trainModel:\n",
    "    \n",
    "    def __init__(self, train_data_path, config_path):\n",
    "        \n",
    "        self.train_data_path = train_data_path\n",
    "        self.config_path = config_path\n",
    "        self.model_directory = None\n",
    "        \n",
    "    def startTraining(self):\n",
    "        \n",
    "        print (\"training nlu model\")\n",
    "        training_data = load_data(self.train_data_path)\n",
    "        trainer = Trainer(config.load(self.config_path))\n",
    "        trainer.train(training_data)       \n",
    "        self.model_directory = trainer.persist('./nluModels/',  fixed_model_name = 'rasa_nlu_model')\n",
    "        print (\"training nlu completed\")\n",
    "training_data = \"./trainingData.json\"\n",
    "training_data = \"./nlu.md\"\n",
    "conf_path = \"./nlu_config.yml\"\n",
    "# print (config.load(load_data(training_data)))\n",
    "# config_path = \"./nlu_config.yml\"\n",
    "# conf_path = \"./spacy_config.yml\"\n",
    "train = trainModel(training_data, conf_path)\n",
    "# #start training\n",
    "train.startTraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert natural sentences to queries\n",
    "\n",
    "To connect with database, Neo4j Python driver is officially supported by Neo4j and connects to the database using the binary protocol.\n",
    "\n",
    "\n",
    "**Pypher** library to convert sentences to queries is used. \n",
    "\n",
    "**Issues** Rasa returns entites in lowercase, so it is not possible to query to neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: \n",
      " hey look for visualization of spi.PersistentComponentDescriptionUpdater external Types\n",
      "--------------------------------------------\n",
      "Intent:  greet\n",
      "entity type:  None\n",
      "entity value:  None\n",
      "=======================================\n",
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.26363656086530923\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.26363656086530923\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_affirm\",\n",
      "      \"confidence\": 0.24491830775904003\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_deny\",\n",
      "      \"confidence\": 0.18752661005124985\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_great\",\n",
      "      \"confidence\": 0.12714357179329808\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.12130248300597567\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_unhappy\",\n",
      "      \"confidence\": 0.05547246652512696\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hey look for visualization of spi.PersistentComponentDescriptionUpdater external Types\"\n",
      "}\n",
      "\n",
      " no Query written regarding this intention\n",
      "Intent is: \n",
      "  greet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/rasa_nlu/extractors/entity_synonyms.py:85: UserWarning: Failed to load synonyms file from '/home/ramesh/github/Databases/neo4j/neo4j_model/notebook/./nluModels/default/rasa_nlu_model/entity_synonyms.json'\n",
      "  \"\".format(entity_synonyms_file))\n"
     ]
    }
   ],
   "source": [
    "class GenerateQuery:\n",
    "    \n",
    "    def __init__(self, train, sentence):\n",
    "        \n",
    "        self.interpret = Interpreter.load(train.model_directory)\n",
    "        self.extracted_intents = None\n",
    "        self.extracted_entities = None\n",
    "        self.extracted_values = None # entities values\n",
    "        self.prediction = None\n",
    "        self.pypherObject = Pypher()\n",
    "        self.uri = \"bolt://localhost:7687\"\n",
    "        self.driver = GraphDatabase.driver(self.uri, auth=(\"neo4j\", \"123456\"))\n",
    "        self.sentence = sentence\n",
    "        \n",
    "    def predictIntentionAndEntity(self):\n",
    "        \n",
    "        self.prediction = self.interpret.parse(self.sentence)\n",
    "        \n",
    "        if len(self.prediction.get(\"entities\")) > 0:\n",
    "            \n",
    "            self.extracted_entities = self.prediction.get(\"entities\")[0]['entity']\n",
    "            self.extracted_values = self.prediction.get(\"entities\")[0]['value']\n",
    "            self.start_position = self.prediction.get(\"entities\")[0]['start']\n",
    "            self.end_position = self.prediction.get(\"entities\")[0]['end']\n",
    "            \n",
    "#             print (self.extracted_values)\n",
    "\n",
    "        self.extracted_intents = self.prediction.get(\"intent\")['name']\n",
    "\n",
    "        print (\"Intent: \", self.extracted_intents)\n",
    "        print (\"entity type: \", self.extracted_entities)\n",
    "        print (\"entity value: \", self.extracted_values)\n",
    "        print (\"=======================================\")\n",
    "        print(json.dumps(self.prediction, indent=2))\n",
    "\n",
    "    \n",
    "    def convertTextToQuery(self):\n",
    "\n",
    "\n",
    "        if self.extracted_intents == 'showGeneralInformation':\n",
    "            \n",
    "            \n",
    "            # p.CREATE.node('user', 'User', Name='Jim')\n",
    "            # p.Match.node('a', labels='bundles').relationship('r').node('b', 'PackagesImports').RETURN('a', 'b', 'r')\n",
    "            text = self.sentence[self.start_position:self.end_position]\n",
    "#             print (\"========================================================\")\n",
    "#             print (text)\n",
    "            self.pypherObject.Match.node('u', labels=self.extracted_entities).WHERE.u.property('name') == self.extracted_values\n",
    "            query = str(self.pypherObject.RETURN.u)\n",
    "            params = self.pypherObject.bound_params\n",
    "            print (\"\\n ========== generated queries ===========\")\n",
    "            print (query)\n",
    "            print (params)\n",
    "            \n",
    "            with self.driver.session() as  session:\n",
    "                result = session.run(str(self.pypherObject), **dict(self.pypherObject.bound_params))\n",
    "#                 result = session.run(str(p))\n",
    "                print (\"\\n ========= result from neo4j ============ \\n\")\n",
    "                print(result.data())\n",
    "            \n",
    "        elif self.extracted_intents == 'getSecondLevelInformation':\n",
    "            print (\"get second level infor\")\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print (\"\\n no Query written regarding this intention\")\n",
    "            print (\"Intent is: \\n \", self.extracted_intents)\n",
    "\n",
    "    \n",
    "sentence = \"hey look for visualization of spi.PersistentComponentDescriptionUpdater external Types\"\n",
    "# sentence = \"Bye\"\n",
    "# sentence = \"list packages.24 packages available in Car bundle\"\n",
    "print (\"Original sentence: \\n\", sentence)\n",
    "print (\"--------------------------------------------\")\n",
    "gQuery = GenerateQuery(train, sentence)\n",
    "gQuery.predictIntentionAndEntity()\n",
    "gQuery.convertTextToQuery()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasa Core\n",
    "\n",
    "First we need to create training examples >> stories.md\n",
    "\n",
    "A story starts with ``##`` followed by a name (the name is optional). lines that start with ``*`` are messages sent by the user.\n",
    "\n",
    "Lines that start with ``-`` are actions taken by your bot. In this case all of our actions are just messages sent back to the user, like ``utter_greet``, but in general an action can do anything, including calling an API and interacting with the outside world.\n",
    "\n",
    "### domain.yml\n",
    "\n",
    " Consists of 5 elements: \n",
    "         i. Slots: helps to keep context of the conversation. Like if we want to know whether of particular location, it should know what information to call from weather api\n",
    "         \n",
    "         ii. intents: these intents are same that are described in nlu model.\n",
    "         \n",
    "         iii. entities: \n",
    "         \n",
    "         iv. templates: it describes what msg chatbot has to send back once action is predicted. \n",
    "         \n",
    "         \n",
    "         v. actions: List of actions, and their execution once they are predicted. actions can be by default as well as custom. (three actions: utter, custom, by_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training nlu model\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "training nlu completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "class rasaCore:\n",
    "    \n",
    "    def __init__(self, domain_path, model_path, stories_path):\n",
    "        \n",
    "        self.domain_path = domain_path\n",
    "        self.model_path = model_path\n",
    "        self.train_data_path = stories_path\n",
    "        self.interpreter = RasaNLUInterpreter(\"./nluModels/default/rasa_nlu_model/\")\n",
    "        \n",
    "    def trainCoreModel(self):\n",
    "        \n",
    "        agent = Agent(self.domain_path, policies = [MemoizationPolicy(), KerasPolicy()], \n",
    "                          interpreter=self.interpreter)\n",
    "        data = agent.load_data(self.train_data_path)\n",
    "        agent.train(data, augmentation_factor = 50,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 10,\n",
    "                    validation_split = 0.2)\n",
    "        agent.persist(self.model_path)\n",
    "    \n",
    "    def generateIntentAndEntity(self, message):\n",
    "        \n",
    "        parsed_nlu_msg = self.interpreter.parse(message)\n",
    "        print(json.dumps(parsed_nlu_msg, indent=2))\n",
    "        \n",
    "    def talkWithBot(self, message):\n",
    "        \n",
    "        self.generateIntentAndEntity(message)\n",
    "        agent = Agent.load(self.model_path)\n",
    "        print (\"\\n ============================= Core response ============================= \\n\")\n",
    "        print (agent.handle_text(message))\n",
    "        \n",
    "# call rasa nlu \n",
    "training_data = \"nlu.md\"\n",
    "conf_path = \"nlu_config.yml\"\n",
    "train = trainModel(training_data, conf_path)\n",
    "# #start training\n",
    "train.startTraining()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training rasa core started \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramesh/anaconda3/lib/python3.6/site-packages/rasa_nlu/extractors/entity_synonyms.py:85: UserWarning: Failed to load synonyms file from './nluModels/default/rasa_nlu_model/entity_synonyms.json'\n",
      "  \"\".format(entity_synonyms_file))\n",
      "Processed Story Blocks: 100%|██████████| 3/3 [00:00<00:00, 38.85it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|██████████| 3/3 [00:00<00:00, 77.15it/s, # trackers=3]\n",
      "Processed Story Blocks: 100%|██████████| 3/3 [00:00<00:00, 78.73it/s, # trackers=12]\n",
      "Processed Story Blocks: 100%|██████████| 3/3 [00:00<00:00, 55.17it/s, # trackers=20]\n",
      "Processed actions: 79it [00:00, 254.14it/s, # examples=79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 10)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                5504      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 198       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 5,702\n",
      "Trainable params: 5,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 63 samples, validate on 16 samples\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 1.7220 - acc: 0.3651 - val_loss: 1.6621 - val_acc: 0.5625\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6671 - acc: 0.4603 - val_loss: 1.6045 - val_acc: 0.5625\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.6022 - acc: 0.4762 - val_loss: 1.5535 - val_acc: 0.5625\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.5615 - acc: 0.4921 - val_loss: 1.5005 - val_acc: 0.5625\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.5018 - acc: 0.4921 - val_loss: 1.4398 - val_acc: 0.5625\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4494 - acc: 0.4921 - val_loss: 1.3773 - val_acc: 0.5625\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 1.4030 - acc: 0.4921 - val_loss: 1.3213 - val_acc: 0.5625\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3758 - acc: 0.4921 - val_loss: 1.2929 - val_acc: 0.5625\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3385 - acc: 0.4921 - val_loss: 1.2603 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.3205 - acc: 0.4921 - val_loss: 1.2308 - val_acc: 0.5625\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2527 - acc: 0.4921 - val_loss: 1.2096 - val_acc: 0.5625\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2750 - acc: 0.4921 - val_loss: 1.1965 - val_acc: 0.5625\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2628 - acc: 0.4921 - val_loss: 1.1853 - val_acc: 0.5625\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2429 - acc: 0.4921 - val_loss: 1.1775 - val_acc: 0.5625\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2174 - acc: 0.4921 - val_loss: 1.1620 - val_acc: 0.5625\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2170 - acc: 0.5079 - val_loss: 1.1505 - val_acc: 0.5625\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.2219 - acc: 0.4921 - val_loss: 1.1425 - val_acc: 0.5625\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1683 - acc: 0.4921 - val_loss: 1.1293 - val_acc: 0.5625\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1843 - acc: 0.4921 - val_loss: 1.1198 - val_acc: 0.5625\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1630 - acc: 0.4921 - val_loss: 1.1126 - val_acc: 0.5625\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1562 - acc: 0.4921 - val_loss: 1.1166 - val_acc: 0.5625\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1418 - acc: 0.4921 - val_loss: 1.1089 - val_acc: 0.5625\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1073 - acc: 0.5079 - val_loss: 1.1033 - val_acc: 0.5625\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1217 - acc: 0.5079 - val_loss: 1.0862 - val_acc: 0.5625\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0880 - acc: 0.4921 - val_loss: 1.0717 - val_acc: 0.5625\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0895 - acc: 0.5079 - val_loss: 1.0598 - val_acc: 0.5625\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.1004 - acc: 0.4921 - val_loss: 1.0471 - val_acc: 0.5625\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.1076 - acc: 0.5079 - val_loss: 1.0451 - val_acc: 0.5625\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0633 - acc: 0.5238 - val_loss: 1.0449 - val_acc: 0.5625\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0591 - acc: 0.5397 - val_loss: 1.0320 - val_acc: 0.5625\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0614 - acc: 0.5079 - val_loss: 1.0287 - val_acc: 0.5625\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0242 - acc: 0.5238 - val_loss: 1.0114 - val_acc: 0.5625\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0116 - acc: 0.5397 - val_loss: 1.0057 - val_acc: 0.5625\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.0067 - acc: 0.5238 - val_loss: 0.9863 - val_acc: 0.5625\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9763 - acc: 0.5397 - val_loss: 0.9836 - val_acc: 0.5625\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9821 - acc: 0.5397 - val_loss: 0.9727 - val_acc: 0.5625\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9566 - acc: 0.5556 - val_loss: 0.9539 - val_acc: 0.5625\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9537 - acc: 0.5714 - val_loss: 0.9360 - val_acc: 0.5625\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.9574 - acc: 0.5714 - val_loss: 0.9224 - val_acc: 0.5625\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9333 - acc: 0.5873 - val_loss: 0.9019 - val_acc: 0.6250\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9314 - acc: 0.6190 - val_loss: 0.8873 - val_acc: 0.5625\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8755 - acc: 0.6032 - val_loss: 0.8822 - val_acc: 0.5625\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8881 - acc: 0.6032 - val_loss: 0.8602 - val_acc: 0.5625\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8989 - acc: 0.5873 - val_loss: 0.8492 - val_acc: 0.6250\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8598 - acc: 0.6825 - val_loss: 0.8468 - val_acc: 0.6250\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8026 - acc: 0.7460 - val_loss: 0.8290 - val_acc: 0.6250\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8258 - acc: 0.6508 - val_loss: 0.8134 - val_acc: 0.6875\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.8364 - acc: 0.6667 - val_loss: 0.7981 - val_acc: 0.6875\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8354 - acc: 0.6984 - val_loss: 0.7952 - val_acc: 0.6875\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7659 - acc: 0.7619 - val_loss: 0.7670 - val_acc: 0.6875\n",
      "training rasa core completed \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# core \n",
    "print (\"training rasa core started \\n\")\n",
    "core = rasaCore(\"./domain.yml\",\"./coreModels/dialogue\",\"./stories.md\")\n",
    "core.trainCoreModel()\n",
    "print (\"training rasa core completed \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.4824691320214803\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.4824691320214803\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_affirm\",\n",
      "      \"confidence\": 0.22989382107835482\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.105868055923436\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_deny\",\n",
      "      \"confidence\": 0.07919541028626577\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_great\",\n",
      "      \"confidence\": 0.056341546742784326\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_unhappy\",\n",
      "      \"confidence\": 0.046232033947678705\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "msg = \"hi\"\n",
    "core.generateIntentAndEntity(msg)\n",
    "# result = core.talkWithBot(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"greet\",\n",
      "    \"confidence\": 0.4824691320214803\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.4824691320214803\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_affirm\",\n",
      "      \"confidence\": 0.22989382107835482\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.105868055923436\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_deny\",\n",
      "      \"confidence\": 0.07919541028626577\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_great\",\n",
      "      \"confidence\": 0.056341546742784326\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"mood_unhappy\",\n",
      "      \"confidence\": 0.046232033947678705\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"hi\"\n",
      "}\n",
      "\n",
      " ============================= Core response ============================= \n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "core.talkWithBot(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (u:`service`) WHERE u.`name` = $NEO_2fc89_0 RETURN u\n",
      "[{'u': <Node id=8582 labels={'service'} properties={'name': 'de.rcenvironment.core.component.registration.api.Registerable', 'className': 'http://www.example.org/OSGiApplicationModel#//Service'}>}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"123456\"))\n",
    "b = 'de.rcenvironment.core.component.registration.api.Registerable'\n",
    "# de.rcenvironment.core.component.registration.api.Registerable\n",
    "p = Pypher()\n",
    "# p.CREATE.node('user', 'User', Name='Jim')\n",
    "# p.Match.node('a', labels='bundles').relationship('r').node('b', 'PackagesImports').RETURN('a', 'b', 'r')\n",
    "p.Match.node('u', labels='service').WHERE.u.property('name') == b\n",
    "p.RETURN.u\n",
    "print (str(p))\n",
    "with driver.session() as  session:\n",
    "    result = session.run(str(p), **dict(p.bound_params))\n",
    "#     result = session.run(str(p))\n",
    "\n",
    "    print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pypher with py2neo (fails due to not compatible structure of query returned by pypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATCH (u:`bundles`) WHERE u.`name` = $NEO_50b06_0 RETURN u\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NEO_5ee81_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-3633fe16acd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound_params\u001b[0m \u001b[0;31m# {'NEO_9326c_1': 'Mark'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcypher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NEO_5ee81_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# graph.run(qur).data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NEO_5ee81_0'"
     ]
    }
   ],
   "source": [
    "p = Pypher()\n",
    "b = 'RCE XML Merger Component GUI'\n",
    "a = 'bundles.2/'\n",
    "# p.Match.node('bundles')\n",
    "\n",
    "# qur = p.Match.node('a', labels='bundles').relationship('r').node('b', 'PackagesImports').RETURN('a', 'b', 'r')\n",
    "\n",
    "# qur = p.MATCH.node('u', labels='bundles').WHERE.u.__name__ == 'RCE XML Merger Component GUI'\n",
    "p.Match.node('u', labels='bundles').WHERE.u.property('name') == b\n",
    "p.RETURN.u\n",
    "\n",
    "# p.MATCH.node('a', labels=b).WHERE.a.__name__ == val\n",
    "\n",
    "cypher = str(p) # MATCH (mark:`Person`) WHERE mark.`name` = NEO_9326c_1 RETURN mark\n",
    "params = p.bound_params # {'NEO_9326c_1': 'Mark'}\n",
    "print (cypher)\n",
    "print (params['NEO_5ee81_0'])\n",
    "# graph.run(qur).data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
